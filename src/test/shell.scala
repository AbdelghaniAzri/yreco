/**
 * Created by yawo on 15/10/15.
 */
/*

import java.io.{File, PrintWriter}

import com.yreco.YrecoIntSerializer._
import edu.berkeley.cs.amplab.spark.indexedrdd.IndexedRDD
import org.apache.hadoop.hbase.HBaseConfiguration
import org.apache.hadoop.hbase.client.Result
import org.apache.hadoop.hbase.io.ImmutableBytesWritable
import org.apache.hadoop.hbase.mapreduce.TableInputFormat
import org.apache.hadoop.hbase.util.Bytes
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry, RowMatrix}
import org.apache.spark.mllib.recommendation.{ALS, MatrixFactorizationModel, Rating}
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

import scala.collection.mutable.{LinkedHashSet, ListMap}
import scala.util.Try

import scala.util.Try
import com.yreco.RecommenderDemo._
loadRatings
val rank=20
trainModel
val nMaxSims=20
 */